import { useEffect, useRef, useState } from "react";
import { FaceLandmarker, HandLandmarker, FilesetResolver, DrawingUtils } from "@mediapipe/tasks-vision";
import OBSWebSocket from "obs-websocket-js";
import { sendTriggerEvent } from "../lib/api";
import "./FaceDetector.css";

const REAL_SCENE = "REAL";
const FAKE_SCENE = "FAKE";

const FaceDetector = ({ onDistraction }) => {
    const videoRef = useRef(null);
    const canvasRef = useRef(null);

    // Fake video elements (ÌîÑÎ°†Ìä∏ ÎØ∏Î¶¨Î≥¥Í∏∞/ÎÇ¥Î∂Ä Î°úÏßÅÏö©ÏúºÎ°ú Ïú†ÏßÄ Í∞ÄÎä•)
    const fakeVideoRef = useRef(null);

    // AI Models (MediaPipe)
    const [faceLandmarker, setFaceLandmarker] = useState(null);
    const [handLandmarker, setHandLandmarker] = useState(null);

    // State
    const [webcamRunning, setWebcamRunning] = useState(false);
    const [inputText, setInputText] = useState("");

    // Distraction State
    const [isDistracted, setIsDistracted] = useState(false);
    const [distractionReason, setDistractionReason] = useState("");
    const [botReaction, setBotReaction] = useState(null);

    // Recording & Blending State (fakeVideoUrlÏùÄ Í∑∏ÎÉ• ÎÇ¥Î∂Ä ÌëúÏãú/ÌÖåÏä§Ìä∏Ïö©Ïù¥Î©¥ Ïú†ÏßÄ)
    const [fakeVideoUrl, setFakeVideoUrl] = useState(null);
    const [isRecording, setIsRecording] = useState(false);
    const [blendRatio, setBlendRatio] = useState(0); // UI ÌëúÏãúÏö©ÏúºÎ°úÎßå ÎÇ®Í≤®ÎèÑ Îê®
    const recordingChunks = useRef([]);
    const mediaRecorderRef = useRef(null);

    // OBS State
    const obsRef = useRef(null);
    const [obsConnected, setObsConnected] = useState(false);

    const OBS_URL = "ws://127.0.0.1:4455";
    const OBS_PASSWORD = "CDeP1CouhTyM5F1T";

    // AI Backend WebSocket (Î∞òÏùëÎ¥áÏö© Ïú†ÏßÄ)
    const aiWsRef = useRef(null);
    const [aiConnected, setAiConnected] = useState(false);

    // Refs for loop control
    const requestRef = useRef(null);
    const runningRef = useRef(false);
    const lastVideoTimeRef = useRef(-1);
    const distractionStartTimeRef = useRef(null);

    const runningMode = "VIDEO";

    // ‚úÖ OBS Ïó∞Í≤∞ (StrictMode ÏïàÏ†Ñ)
    useEffect(() => {
        let cancelled = false;

        const obs = new OBSWebSocket();
        obsRef.current = obs;

        obs.on("ConnectionOpened", () => {
            console.log("OBS ConnectionOpened");
        });

        obs.on("ConnectionClosed", (e) => {
            console.log("OBS ConnectionClosed:", e);
            if (!cancelled) setObsConnected(false);
        });

        (async () => {
            try {
                await obs.connect(OBS_URL, OBS_PASSWORD);

                if (cancelled) {
                    await obs.disconnect().catch(() => { });
                    return;
                }

                console.log("‚úÖ OBS Connected");
                setObsConnected(true);
            } catch (e) {
                if (!cancelled) {
                    console.error("‚ùå OBS Connection Failed", e);
                    setObsConnected(false);
                }
            }
        })();

        return () => {
            cancelled = true;
            obs.disconnect().catch(() => { });
            obsRef.current = null;
        };
    }, []);

    // 1. Initialize OBS & Models & AI WebSocket
    useEffect(() => {
        // connectOBS();
        connectAI();

        const createLandmarkers = async () => {
            console.log("üîÑ Loading MediaPipe models...");
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
            );

            const face = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath:
                        "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                    delegate: "GPU",
                },
                outputFaceBlendshapes: true,
                outputFacialTransformationMatrixes: true,
                runningMode,
                numFaces: 1,
            });
            setFaceLandmarker(face);
            console.log("‚úÖ FaceLandmarker loaded");

            const hand = await HandLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath:
                        "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
                    delegate: "GPU",
                },
                runningMode,
                numHands: 1,
            });
            setHandLandmarker(hand);
            console.log("‚úÖ HandLandmarker loaded");
        };

        createLandmarkers();

        return () => {
            try { obsRef.current?.disconnect(); } catch { }
            try { aiWsRef.current?.close(); } catch { }
            if (requestRef.current) cancelAnimationFrame(requestRef.current);
        };
    }, []);

    // // 2. OBS Connection
    // const connectOBS = async () => {
    //     try {
    //         obsRef.current.on("ConnectionClosed", (e) => {
    //             console.log("OBS ConnectionClosed:", e); // code/reason ÎÇòÏò§ÎäîÏßÄ ÌôïÏù∏
    //         });

    //         obsRef.current.on("ConnectionOpened", () => {
    //             console.log("OBS ConnectionOpened");
    //         });

    //         await obsRef.current.connect("ws://localhost:4455", "CDeP1CouhTyM5FTT");
    //         console.log("‚úÖ OBS Connected");
    //         setObsConnected(true);
    //     } catch (error) {
    //         console.error("‚ùå OBS Connection Failed", error);
    //         setObsConnected(false);
    //     }
    // };

    const switchOBSScene = async (sceneName) => {
        const obs = obsRef.current;
        if (!obsConnected) return;
        try {
            await obs.call("SetCurrentProgramScene", { sceneName });
            console.log(`üé¨ OBS Scene: ${sceneName}`);
        } catch (e) {
            console.warn("‚ö†Ô∏è OBS Switch Failed:", e);
        }
    };

    // ‚úÖ ÌïµÏã¨: Îî¥Ïßì ÏÉÅÌÉúÍ∞Ä Î∞îÎÄî Îïå OBS Ïî¨ Ï†ÑÌôòÎßå ÌïúÎã§
    useEffect(() => {
        if (!obsConnected) return;

        // onDistraction ÏΩúÎ∞± ÌïÑÏöîÌïòÎ©¥ Ïó¨Í∏∞ÏÑú Ìò∏Ï∂ú
        onDistraction?.(isDistracted);

        // ‚úÖ 1) OBS Ïî¨ Ï†ÑÌôò
        switchOBSScene(isDistracted ? FAKE_SCENE : REAL_SCENE);

        // ‚úÖ 2) Î∞±ÏóîÎìúÎ°ú Ìä∏Î¶¨Í±∞ Ïù¥Î≤§Ìä∏ Ï†ÑÏÜ°
        sendTriggerEvent({
            distracted: isDistracted,
            reason: distractionReason || null,
            ts: Date.now() / 1000,
            // pitch/yaw/confidenceÎ•º Í∞ñÍ≥† ÏûàÏúºÎ©¥ Í∞ôÏù¥ Î≥¥ÎÇ¥Î©¥ Îçî Ï¢ãÏùå
        }).catch(() => { });
    }, [isDistracted, obsConnected]);

    // 3. AI Backend WebSocket (Î∞òÏùëÎ¥á)
    const connectAI = () => {
        if (aiWsRef.current && aiWsRef.current.readyState === WebSocket.OPEN) return;

        const ws = new WebSocket("ws://127.0.0.1:8000/ws/ai");
        aiWsRef.current = ws;

        ws.onopen = () => {
            console.log("‚úÖ AI WS open");
            setAiConnected(true);
            // ÏÑúÎ≤ÑÏóê ping Ìïú Î≤à Î≥¥ÎÇ¥ÏÑú ÏùëÎãµ ÌôïÏù∏ÌïòÍ≥† Ïã∂ÏúºÎ©¥:
            ws.send(JSON.stringify({ type: "ping" }));
        };

        ws.onmessage = (e) => {
            try {
                const data = JSON.parse(e.data);
                // ÏÑúÎ≤Ñ hello Î∞õÏúºÎ©¥ Ïó∞Í≤∞ ÌôïÏ†ï
                if (data.type === "hello") {
                    console.log("‚úÖ AI hello:", data);
                    setAiConnected(true);
                    return;
                }
                if (data.type === "reaction") {
                    setBotReaction(data.reaction);
                    setTimeout(() => setBotReaction(null), 5000);
                }
            } catch {
                // ÌÖçÏä§Ìä∏ pong Í∞ôÏùÄÍ±∞Îäî Î¨¥Ïãú Í∞ÄÎä•
            }
        };

        ws.onerror = (err) => {
            console.error("‚ùå AI WS error", err);
            setAiConnected(false);
        };

        ws.onclose = () => {
            console.log("‚ùå AI WS close");
            setAiConnected(false);
            // ÌïÑÏöîÌïòÎ©¥ Ïû¨Ïó∞Í≤∞
            setTimeout(connectAI, 1500);
        };
    };

    // (ÏÑ†ÌÉù) startRecordingÏùÄ Ïú†ÏßÄ Í∞ÄÎä•(ÌîÑÎ°†Ìä∏ ÎÇ¥ fake ÌÖåÏä§Ìä∏Ïö©)
    const startRecording = (stream) => {
        setIsRecording(true);
        recordingChunks.current = [];

        const recorder = new MediaRecorder(stream, {
            mimeType: "video/webm;codecs=vp8",
        });

        recorder.ondataavailable = (e) => {
            if (e.data.size > 0) recordingChunks.current.push(e.data);
        };

        recorder.onstop = () => {
            const blob = new Blob(recordingChunks.current, { type: "video/webm" });
            const url = URL.createObjectURL(blob);
            setFakeVideoUrl(url);
            setIsRecording(false);
        };

        recorder.start();
        mediaRecorderRef.current = recorder;

        setTimeout(() => {
            if (mediaRecorderRef.current?.state === "recording") {
                mediaRecorderRef.current.stop();
            }
        }, 5000);
    };

    // Main Prediction Loop
    const predictWebcam = async () => {
        const video = videoRef.current;
        const canvas = canvasRef.current;
        if (!runningRef.current || !video || !canvas || !faceLandmarker || !handLandmarker) return;

        const startTimeMs = performance.now();

        if (video.videoWidth > 0 && video.videoHeight > 0 && video.currentTime !== lastVideoTimeRef.current) {
            lastVideoTimeRef.current = video.currentTime;

            const handResults = handLandmarker.detectForVideo(video, startTimeMs);
            const handsDetected = handResults.landmarks?.length > 0;

            const faceResults = faceLandmarker.detectForVideo(video, startTimeMs);

            let potentialDistraction = false;
            let currentReason = "";

            if (handsDetected && faceResults.faceLandmarks?.length > 0) {
                potentialDistraction = true;
                currentReason = "Hand Detected";
            }

            if (faceResults.facialTransformationMatrixes?.length > 0) {
                const matrix = faceResults.facialTransformationMatrixes[0].data;
                const landmarks = faceResults.faceLandmarks[0];

                const pitchRad = Math.atan2(matrix[6], matrix[10]);
                const pitchDeg = pitchRad * (180 / Math.PI);
                const yawDeg = Math.atan2(-matrix[2], matrix[0]) * (180 / Math.PI);
                const ear = calculateEAR(landmarks);

                if (Math.abs(pitchDeg) > 15) {
                    potentialDistraction = true;
                    currentReason = `Head Nodding (${Math.round(pitchDeg)}¬∞)`;
                } else if (Math.abs(yawDeg) > 30) {
                    potentialDistraction = true;
                    currentReason = `Head Turning (${Math.round(yawDeg)}¬∞)`;
                } else if (ear < 0.24) {
                    potentialDistraction = true;
                    currentReason = "Drowsiness";
                }
            }

            // 750ms Ïú†ÏßÄ Ï°∞Í±¥
            if (potentialDistraction) {
                if (distractionStartTimeRef.current === null) {
                    distractionStartTimeRef.current = Date.now();
                } else if (Date.now() - distractionStartTimeRef.current > 750) {
                    setIsDistracted(true);
                    setDistractionReason(currentReason);
                }
            } else {
                distractionStartTimeRef.current = null;
                setIsDistracted(false);
            }

            // Draw landmarks (ÌîÑÎ°†Ìä∏ Î™®ÎãàÌÑ∞Ïö©)
            const ctx = canvas.getContext("2d");
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            const drawingUtils = new DrawingUtils(ctx);

            if (faceResults.faceLandmarks) {
                for (const lms of faceResults.faceLandmarks) {
                    drawingUtils.drawConnectors(lms, FaceLandmarker.FACE_LANDMARKS_TESSELATION, {
                        color: "#C0C0C070",
                        lineWidth: 1,
                    });
                }
            }
            if (handResults.landmarks) {
                for (const lms of handResults.landmarks) {
                    drawingUtils.drawConnectors(lms, HandLandmarker.HAND_CONNECTIONS, {
                        color: "#FF0000",
                        lineWidth: 2,
                    });
                }
            }
        }

        if (runningRef.current) requestRef.current = requestAnimationFrame(predictWebcam);
    };

    // Camera Toggle (OBS Virtual Camera Ïö∞ÏÑ†)
    const enableCam = async () => {
        if (!faceLandmarker || !handLandmarker) {
            alert("Please wait for MediaPipe models to load...");
            return;
        }

        // STOP
        if (webcamRunning) {
            setWebcamRunning(false);
            runningRef.current = false;
            setIsDistracted(false);
            if (requestRef.current) cancelAnimationFrame(requestRef.current);

            const stream = videoRef.current?.srcObject;
            if (stream) {
                stream.getTracks().forEach((t) => t.stop());
                videoRef.current.srcObject = null;
            }
            return;
        }

        // START
        setWebcamRunning(true);
        runningRef.current = true;
        setIsDistracted(false);

        try {
            // ‚úÖ 0) Í∂åÌïú Î®ºÏ†Ä ÌöçÎìùÌï¥ÏÑú device label Ï±ÑÏö∞Í∏∞ (Ï§ëÏöî!)
            const tmp = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            tmp.getTracks().forEach((t) => t.stop());

            // ‚úÖ 1) Ïû•Ïπò ÎÇòÏó¥
            const devices = await navigator.mediaDevices.enumerateDevices();
            const videoDevices = devices.filter((d) => d.kind === "videoinput");

            // ‚úÖ 2) OBS/Virtual Ïö∞ÏÑ† ÏÑ†ÌÉù
            const obsCam =
                videoDevices.find((d) => (d.label || "").toLowerCase().includes("obs")) ||
                videoDevices.find((d) => (d.label || "").toLowerCase().includes("virtual"));

            // ‚úÖ 3) ÏóÜÏúºÎ©¥ ÏùºÎ∞ò ÏõπÏ∫† fallback
            const realCam = videoDevices.find((d) => {
                const label = (d.label || "").toLowerCase();
                return !label.includes("obs") && !label.includes("virtual");
            });

            const selected = obsCam || realCam || videoDevices[0];

            if (!selected) throw new Error("No video input device found");

            console.log("üé• Selected camera:", selected.label || selected.deviceId);

            // ‚úÖ 4) ÏÑ†ÌÉùÌïú Ïπ¥Î©îÎùºÎ°ú Ïä§Ìä∏Î¶º ÏãúÏûë
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    deviceId: selected.deviceId ? { exact: selected.deviceId } : undefined,
                    width: { ideal: 1280 },
                    height: { ideal: 720 },
                },
                audio: false,
            });

            videoRef.current.srcObject = stream;

            // loadeddata Ï§ëÎ≥µ Î∞©ÏßÄ: once ÏòµÏÖò ÏÇ¨Ïö©
            videoRef.current.addEventListener(
                "loadeddata",
                () => {
                    predictWebcam();

                    // ‚ö†Ô∏è OBS Í∞ÄÏÉÅÏπ¥Î©îÎùº Ïä§Ìä∏Î¶ºÏóê fake ÎÖπÌôîÎäî ÏùòÎØ∏Í∞Ä ÏóÜÍ≥† Ï∂©Îèå Í∞ÄÎä•ÏÑ±Îßå Ïò¨Î¶º
                    // ÌïÑÏöîÌïòÎ©¥ ÏïÑÎûò Ï£ºÏÑù Ìï¥Ï†ú
                    // if (!fakeVideoUrl) startRecording(stream);
                },
                { once: true }
            );
        } catch (err) {
            alert(`Webcam error: ${err.message}`);
            setWebcamRunning(false);
            runningRef.current = false;
        }
    };


    const sendMacro = async (app) => {
        try {
            await fetch("http://localhost:8000/control/macro", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ text: inputText, app }),
            });
        } catch (err) {
            console.error(err);
        }
    };

    return (
        <div className="face-detector">
            <div style={{ position: "relative", width: "640px", height: "480px" }}>
                <video
                    ref={videoRef}
                    style={{ width: "100%", height: "100%", transform: "scaleX(-1)" }}
                    autoPlay
                    playsInline
                />
                <canvas
                    ref={canvasRef}
                    width="640"
                    height="480"
                    style={{ position: "absolute", left: 0, top: 0, transform: "scaleX(-1)" }}
                />

                {fakeVideoUrl && (
                    <video
                        ref={fakeVideoRef}
                        src={fakeVideoUrl}
                        autoPlay
                        loop
                        muted
                        style={{ display: "none" }}
                    />
                )}

                {isDistracted && (
                    <div style={{
                        position: "absolute", top: "10px", right: "10px",
                        backgroundColor: "rgba(255, 0, 0, 0.7)", color: "white",
                        padding: "5px 10px", borderRadius: "5px", fontWeight: "bold"
                    }}>
                        üö® DISTRACTED: {distractionReason}
                        <br />
                        <small>Blend(UI): {Math.round(blendRatio * 100)}%</small>
                    </div>
                )}

                {isRecording && (
                    <div style={{
                        position: "absolute", top: "10px", left: "10px",
                        backgroundColor: "rgba(255, 165, 0, 0.8)", color: "white",
                        padding: "5px 10px", borderRadius: "5px", fontWeight: "bold"
                    }}>
                        üî¥ Recording fake video...
                    </div>
                )}

                {botReaction && (
                    <div style={{
                        position: "absolute", bottom: "10px", left: "10px",
                        backgroundColor: "rgba(0, 123, 255, 0.9)", color: "white",
                        padding: "8px 12px", borderRadius: "5px", maxWidth: "300px"
                    }}>
                        ü§ñ {botReaction}
                    </div>
                )}
            </div>

            <div className="controls">
                <button onClick={enableCam}>
                    {webcamRunning ? "Stop Camera" : "Start Camera"}
                </button>

                <div style={{ marginLeft: "10px", display: "inline-block", fontSize: "0.9em" }}>
                    OBS: {obsConnected ? "‚úÖ" : "‚ùå"} | AI: {aiConnected ? "‚úÖ" : "‚ùå"}
                    {fakeVideoUrl && " | Fake(Local): ‚úÖ"}
                </div>

                <div className="macro-control" style={{ marginTop: "10px" }}>
                    <input
                        type="text"
                        value={inputText}
                        onChange={(e) => setInputText(e.target.value)}
                        placeholder="Message to type..."
                    />
                    <button onClick={() => sendMacro("zoom")}>Send to Zoom</button>
                    <button onClick={() => sendMacro("discord")}>Send to Discord</button>
                </div>
            </div>
        </div>
    );
};

export default FaceDetector;
