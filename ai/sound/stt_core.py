import speech_recognition as sr
from faster_whisper import WhisperModel
import os
import json
import sys
import queue
import time

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì • (ì´ëª¨ì§€ ì¶œë ¥ìš©)
sys.stdout.reconfigure(encoding='utf-8')

# === Config ë¡œë”© ===
def load_config():
    """config.json íŒŒì¼ì„ ì½ì–´ì„œ ì„¤ì • ë°˜í™˜"""
    config_path = os.path.join(os.path.dirname(__file__), "config.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print("âš ï¸ config.json ì—†ìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©")
        return {
            "triggers": {"keywords": [], "question_patterns": ["?"]},
            "settings": {"device_index": 0, "model_size": "medium", "language": "ko", "sample_rate": 48000}
        }


class GhostEars:
    def __init__(self, config=None):
        """
        config: config.jsonì—ì„œ ë¡œë“œí•œ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        if config is None:
            config = load_config()
        
        self.config = config
        self._apply_config(config)
        
        model_size = self.config.get("settings", {}).get("model_size")
        print(f"--- ğŸ§ [GhostEars] ëª¨ë¸ ë¡œë”© ì¤‘... ({model_size}) ---")
        print(f"ğŸ“Œ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ: {self.trigger_keywords}")
        
        try:
            self.model = WhisperModel(model_size, device="auto", compute_type="int8")
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self.model = None
            
        self.recognizer = sr.Recognizer()
        # ê°€ìƒ ì¼€ì´ë¸” ì†Œë¦¬ëŠ” ì‘ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸í„±ê°’ì„ ë‚®ì¶¤
        self.recognizer.energy_threshold = 100 
        self.recognizer.dynamic_energy_threshold = True
        
        
        # [Queue] ì˜¤ë””ì˜¤ ë°ì´í„° ëŒ€ê¸°ì—´ (ë¹„ë™ê¸° ì²˜ë¦¬ìš©)
        self.audio_queue = queue.Queue()
        
        # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜(ai/sound) ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì • (ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  ì—¬ê¸° ì €ì¥ë¨)
        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.temp_filename = os.path.join(base_dir, "temp_ghost_audio.wav")
        self.transcript_file = os.path.join(base_dir, "transcript.txt")
        
        # [ë¡œê·¸] ëŒ€í™” ë‚´ìš© ì €ì¥ìš© íŒŒì¼ (ì‹œì‘ ì‹œ ì´ˆê¸°í™”)
        with open(self.transcript_file, "w", encoding="utf-8") as f:
            f.write(f"=== [No-Look] ëŒ€í™” ë¡œê·¸ ì‹œì‘ ({model_size}) ===\n")

    def _audio_callback(self, recognizer, audio):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ë””ì˜¤ê°€ ìº¡ì²˜ë˜ë©´ Queueì— ë„£ìŒ"""
        print(f"ğŸ¤ [Audio] ì‹ í˜¸ ê°ì§€ë¨! (ë°ì´í„° í¬ê¸°: {len(audio.get_raw_data())} bytes)")
        self.audio_queue.put(audio)

    def start_listening(self):
        """ë°±ê·¸ë¼ìš´ë“œ ë¦¬ìŠ¤ë‹ ì‹œì‘"""
        try:
            self.source = sr.Microphone(device_index=self.device_index, sample_rate=self.sample_rate)
            print(f"ğŸ‘‚ [Background Listening] ë°±ê·¸ë¼ìš´ë“œ ì²­ì·¨ ì‹œì‘... (Rate: {self.sample_rate}Hz)")
            
            # listen_in_backgroundëŠ” ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë™ì‘í•¨
            self.stopper = self.recognizer.listen_in_background(
                self.source, 
                self._audio_callback, 
                phrase_time_limit=5 # ì‘ë‹µ ì†ë„ë¥¼ ìœ„í•´ ì§§ê²Œ ëŠìŒ
            )
            return True
        except Exception as e:
            print(f"âŒ ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def process_queue(self):
        """Queueì— ìŒ“ì¸ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ì²˜ë¦¬ (ì œë„ˆë ˆì´í„°)"""
        while True:
            try:
                # 0.5ì´ˆë§ˆë‹¤ í í™•ì¸
                audio_data = self.audio_queue.get(timeout=0.5)
            except queue.Empty:
                yield None
                continue
            
            # ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            try:
                print("âš¡ [Processing] ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘...")
                with open(self.temp_filename, "wb") as f:
                    f.write(audio_data.get_wav_data())
                
                segments, info = self.model.transcribe(
                    self.temp_filename, 
                    beam_size=5, 
                    language=self.language,
                    vad_filter=True, 
                    vad_parameters=dict(min_silence_duration_ms=500)
                )
                
                full_text = ""
                for segment in segments:
                    if segment.avg_logprob < -1.0:
                        print(f"ğŸ‘» [Ghost Filter] í™˜ê° ì œê±°ë¨ ({segment.avg_logprob:.2f}): {segment.text}")
                        continue
                    full_text += segment.text
                
                
                final_text = full_text.strip()
                if not final_text:
                    print("ğŸ’¨ [Skipped] ì¸ì‹ëœ ë‚´ìš© ì—†ìŒ (ì¡ìŒ ë˜ëŠ” ì¹¨ë¬µ)")
                    yield None
                    continue
                    
                yield final_text
                
            except Exception as e:
                print(f"âš ï¸ ë³€í™˜ ì¤‘ ì—ëŸ¬: {e}")
                yield None

    def save_to_log(self, text):
        """ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ì €ì¥ (GPTê°€ ì½ì–´ê°ˆ ìš©ë„)"""
        with open(self.transcript_file, "a", encoding="utf-8") as f:
            f.write(f"{text}\n")

    def _apply_config(self, config):
        """ì„¤ì •ê°’ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì ìš©"""
        settings = config.get("settings", {})
        triggers = config.get("triggers", {})
        
        # ì„¤ì •ê°’ ì¶”ì¶œ
        self.device_index = settings.get("device_index", 0)
        self.language = settings.get("language", "ko")
        self.sample_rate = settings.get("sample_rate", 16000)
        
        # íŠ¸ë¦¬ê±° ì„¤ì •
        self.trigger_keywords = triggers.get("keywords", [])
        self.question_patterns = triggers.get("question_patterns", ["?"])

    def reload_config(self):
        """
        config.jsonì„ ë‹¤ì‹œ ì½ì–´ì„œ íŠ¸ë¦¬ê±° ì„¤ì • ê°±ì‹ 
        Frontendì—ì„œ ì„¤ì • ë³€ê²½ í›„ í˜¸ì¶œ
        """
        self.config = load_config()
        self._apply_config(self.config)
        print(f"ğŸ”„ ì„¤ì • ë‹¤ì‹œ ë¡œë“œë¨!")
        print(f"ğŸ“Œ ìƒˆ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ: {self.trigger_keywords}")
        return True

    def check_trigger(self, text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ íŠ¸ë¦¬ê±° ê°ì§€
        Returns: 
            - "KEYWORD": í‚¤ì›Œë“œ ê°ì§€ë¨
            - "QUESTION": ì§ˆë¬¸ íŒ¨í„´ ê°ì§€ë¨
            - None: íŠ¸ë¦¬ê±° ì—†ìŒ
        """
        if not text:
            return None
            
        # 1. í‚¤ì›Œë“œ ì²´í¬ (ì´ë¦„ ë“±)
        for keyword in self.trigger_keywords:
            if keyword in text:
                return ("KEYWORD", keyword)
        
        # 2. ì§ˆë¬¸ íŒ¨í„´ ì²´í¬
        for pattern in self.question_patterns:
            if pattern in text:
                return ("QUESTION", pattern)
        
        return None




# === í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ===
if __name__ == "__main__":
    # Config ë¡œë“œ ë° ì‹œì‘
    config = load_config()
    ears = GhostEars(config)
    
    print("\nğŸš€ [STT ì‹œìŠ¤í…œ ê°€ë™ (Queue Mode)]")
    print(f"ğŸ¯ ê°ì§€í•  í‚¤ì›Œë“œ: {ears.trigger_keywords}")
    print("-" * 40)
    
    # ë°±ê·¸ë¼ìš´ë“œ ë¦¬ìŠ¤ë‹ ì‹œì‘
    if ears.start_listening():
        try:
            # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” Queue ì²˜ë¦¬ ë‹´ë‹¹
            for text in ears.process_queue():
                if text:
                    print(f"â–¶ ì¸ì‹ë¨: {text}")
                    ears.save_to_log(text)
                    
                    trigger = ears.check_trigger(text)
                    if trigger:
                        trigger_type, matched = trigger
                        if trigger_type == "KEYWORD":
                            print(f"ğŸš¨ [ê¸´ê¸‰] í‚¤ì›Œë“œ '{matched}' ê°ì§€!")
                        elif trigger_type == "QUESTION":
                            print(f"â“ [ì§ˆë¬¸ ê°ì§€] ì§ˆë¬¸ íŒ¨í„´ '{matched}' ê°ì§€ë¨")
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ")
            if hasattr(ears, 'stopper'):
                ears.stopper(wait_for_stop=False)