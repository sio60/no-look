import speech_recognition as sr
from faster_whisper import WhisperModel
import os
import json
import sys
import queue
import time
import re

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì • (ì´ëª¨ì§€ ì¶œë ¥ìš©)
sys.stdout.reconfigure(encoding='utf-8')

# === Config ë¡œë”© ===
def load_config():
    """config.json íŒŒì¼ì„ ì½ì–´ì„œ ì„¤ì • ë°˜í™˜"""
    config_path = os.path.join(os.path.dirname(__file__), "config.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print("âš ï¸ config.json ì—†ìŒ. ê¸°ë³¸ê°’ ì‚¬ìš©")
        return {
            "triggers": {"keywords": [], "question_patterns": ["?"]},
            "settings": {"device_index": 0, "model_size": "medium", "language": "ko", "sample_rate": 48000}
        }


class GhostEars:
    def __init__(self, config=None):
        """
        config: config.jsonì—ì„œ ë¡œë“œí•œ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        if config is None:
            config = load_config()
        
        self.config = config
        self._apply_config(config)
        
        model_size = self.config.get("settings", {}).get("model_size")
        print(f"--- ğŸ§ [GhostEars] ëª¨ë¸ ë¡œë”© ì¤‘... ({model_size}) ---")
        print(f"ğŸ“Œ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ: {self.trigger_keywords}")
        
        try:
            self.model = WhisperModel(model_size, device="auto", compute_type="int8")
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self.model = None
            
        self.recognizer = sr.Recognizer()
        # ê°€ìƒ ì¼€ì´ë¸” ì†Œë¦¬ëŠ” ì‘ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸í„±ê°’ì„ ë‚®ì¶¤
        self.recognizer.energy_threshold = 100 
        self.recognizer.dynamic_energy_threshold = True
        
        
        # [Queue] ì˜¤ë””ì˜¤ ë°ì´í„° ëŒ€ê¸°ì—´ (ë¹„ë™ê¸° ì²˜ë¦¬ìš©)
        self.audio_queue = queue.Queue()
        
        # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜(ai/sound) ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì • (ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  ì—¬ê¸° ì €ì¥ë¨)
        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.temp_filename = os.path.join(base_dir, "temp_ghost_audio.wav")
        self.transcript_file = os.path.join(base_dir, "transcript.txt")
        
        # [Memory] ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìš”ì•½/ë§¤í¬ë¡œìš©)
        self.full_history = []
        
        # [ë¡œê·¸] ëŒ€í™” ë‚´ìš© ì €ì¥ìš© íŒŒì¼ (ê¸°ì¡´ ê¸°ë¡ ìœ ì§€í•˜ë©° ì‹œì‘ êµ¬ë¶„ì„ ë§Œ ì¶”ê°€)
        with open(self.transcript_file, "a", encoding="utf-8") as f:
            f.write(f"\n\n--- ğŸš€ [No-Look] ì„¸ì…˜ ì‹œì‘: {time.strftime('%Y-%m-%d %H:%M:%S')} ({model_size}) ---\n")

    def _audio_callback(self, recognizer, audio):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ë””ì˜¤ê°€ ìº¡ì²˜ë˜ë©´ Queueì— ë„£ìŒ"""
        print(f"ğŸ¤ [Audio] ì‹ í˜¸ ê°ì§€ë¨! (ë°ì´í„° í¬ê¸°: {len(audio.get_raw_data())} bytes)")
        self.audio_queue.put(audio)

    def start_listening(self):
        """ë°±ê·¸ë¼ìš´ë“œ ë¦¬ìŠ¤ë‹ ì‹œì‘"""
        try:
            self.source = sr.Microphone(device_index=self.device_index, sample_rate=self.sample_rate)
            print(f"ğŸ‘‚ [Background Listening] ë°±ê·¸ë¼ìš´ë“œ ì²­ì·¨ ì‹œì‘... (Rate: {self.sample_rate}Hz)")
            
            # listen_in_backgroundëŠ” ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë™ì‘í•¨
            self.stopper = self.recognizer.listen_in_background(
                self.source, 
                self._audio_callback, 
                phrase_time_limit=5 # ì‘ë‹µ ì†ë„ë¥¼ ìœ„í•´ ì§§ê²Œ ëŠìŒ
            )
            return True
        except Exception as e:
            print(f"âŒ ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def process_queue(self):
        """Queueì— ìŒ“ì¸ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ì²˜ë¦¬ (ì œë„ˆë ˆì´í„°)"""
        while True:
            try:
                # 0.5ì´ˆë§ˆë‹¤ í í™•ì¸
                audio_data = self.audio_queue.get(timeout=0.5)
            except queue.Empty:
                yield None
                continue
            
            # ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            try:
                print("âš¡ [Processing] ì˜¤ë””ì˜¤ ë³€í™˜ ì¤‘...")
                with open(self.temp_filename, "wb") as f:
                    f.write(audio_data.get_wav_data())
                
                segments, info = self.model.transcribe(
                    self.temp_filename, 
                    beam_size=5, 
                    language=self.language,
                    vad_filter=True, 
                    vad_parameters=dict(min_silence_duration_ms=500)
                )
                
                full_text = ""
                for segment in segments:
                    if segment.avg_logprob < -1.0:
                        print(f"ğŸ‘» [Ghost Filter] í™˜ê° ì œê±°ë¨ ({segment.avg_logprob:.2f}): {segment.text}")
                        continue
                    full_text += segment.text
                
                
                final_text = full_text.strip()
                if not final_text:
                    print("ğŸ’¨ [Skipped] ì¸ì‹ëœ ë‚´ìš© ì—†ìŒ (ì¡ìŒ ë˜ëŠ” ì¹¨ë¬µ)")
                    yield None
                    continue
                    
                yield final_text
                
            except Exception as e:
                print(f"âš ï¸ ë³€í™˜ ì¤‘ ì—ëŸ¬: {e}")
                yield None

    def save_to_log(self, text):
        """ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ ë° ë©”ëª¨ë¦¬ì— ì €ì¥ (GPTê°€ ì½ì–´ê°ˆ ìš©ë„)"""
        timestamp = time.strftime("[%H:%M:%S]")
        entry = f"{timestamp} {text}"
        
        # íŒŒì¼ ì €ì¥
        with open(self.transcript_file, "a", encoding="utf-8") as f:
            f.write(f"{entry}\n")
            
        # ë©”ëª¨ë¦¬ ì €ì¥
        self.full_history.append(entry)

    def get_full_transcript(self):
        """ì§€ê¸ˆê¹Œì§€ì˜ ì „ì²´ ëŒ€í™” ë‚´ìš©ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ ë°˜í™˜"""
        return "\n".join(self.full_history)

    def _apply_config(self, config):
        """ì„¤ì •ê°’ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì ìš©"""
        settings = config.get("settings", {})
        triggers = config.get("triggers", {})
        
        # ì„¤ì •ê°’ ì¶”ì¶œ
        self.device_index = settings.get("device_index", 0)
        self.language = settings.get("language", "ko")
        self.sample_rate = settings.get("sample_rate", 16000)
        
        # íŠ¸ë¦¬ê±° ì„¤ì •
        self.trigger_keywords = triggers.get("keywords", [])
        self.question_patterns = triggers.get("question_patterns", ["?"])

    def reload_config(self):
        """
        config.jsonì„ ë‹¤ì‹œ ì½ì–´ì„œ íŠ¸ë¦¬ê±° ì„¤ì • ê°±ì‹ 
        Frontendì—ì„œ ì„¤ì • ë³€ê²½ í›„ í˜¸ì¶œ
        """
        self.config = load_config()
        self._apply_config(self.config)
        print(f"ğŸ”„ ì„¤ì • ë‹¤ì‹œ ë¡œë“œë¨!")
        print(f"ğŸ“Œ ìƒˆ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ: {self.trigger_keywords}")
        return True

    def check_trigger(self, text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ íŠ¸ë¦¬ê±° ê°ì§€ (ì •ê·œì‹ ê¸°ë°˜ ì§€ëŠ¥í˜• ê°ì§€)
        """
        if not text:
            return None
            
        # ê²€ìƒ‰ í’ˆì§ˆì„ ìœ„í•´ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° ë²„ì „ ì¤€ë¹„
        clean_text = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', text)
        
        # 1. í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.trigger_keywords:
            clean_keyword = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', keyword)
            if clean_keyword in clean_text:
                return ("KEYWORD", keyword)
        
        # 2. ì§ˆë¬¸/ì§€ì‹œ íŒ¨í„´ ì²´í¬ (ì •ê·œì‹ ì§€ì›)
        for pattern in self.question_patterns:
            # íŒ¨í„´ ìì²´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í˜¹ì€ ì •ê·œì‹ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
            clean_pattern = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', pattern)
            if clean_pattern in clean_text:
                return ("QUESTION", pattern)
            
            # ì‹¤ì œ ì •ê·œì‹ ë§¤ì¹­ ì‹œë„
            try:
                if re.search(pattern, text):
                    return ("QUESTION", pattern)
            except:
                continue
        
        return None




# === í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ===
if __name__ == "__main__":
    # Config ë¡œë“œ ë° ì‹œì‘
    config = load_config()
    ears = GhostEars(config)
    
    print("\nğŸš€ [STT ì‹œìŠ¤í…œ ê°€ë™ (Queue Mode)]")
    print(f"ğŸ¯ ê°ì§€í•  í‚¤ì›Œë“œ: {ears.trigger_keywords}")
    print("-" * 40)
    
    # ë°±ê·¸ë¼ìš´ë“œ ë¦¬ìŠ¤ë‹ ì‹œì‘
    if ears.start_listening():
        try:
            # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” Queue ì²˜ë¦¬ ë‹´ë‹¹
            for text in ears.process_queue():
                if text:
                    print(f"â–¶ ì¸ì‹ë¨: {text}")
                    ears.save_to_log(text)
                    
                    trigger = ears.check_trigger(text)
                    if trigger:
                        trigger_type, matched = trigger
                        if trigger_type == "KEYWORD":
                            print(f"ğŸš¨ [ê¸´ê¸‰] í‚¤ì›Œë“œ '{matched}' ê°ì§€!")
                        elif trigger_type == "QUESTION":
                            print(f"â“ [ì§ˆë¬¸ ê°ì§€] ì§ˆë¬¸ íŒ¨í„´ '{matched}' ê°ì§€ë¨")
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ")
            if hasattr(ears, 'stopper'):
                ears.stopper(wait_for_stop=False)